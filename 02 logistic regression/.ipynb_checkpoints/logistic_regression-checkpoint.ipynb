{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import sys\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 12\n",
    "num_rows = 1000\n",
    "seed = 42 # interesting seeds: 28, 32, (42), 56, 58, 63, 91\n",
    "max_epochs = 1000 # for PSO algorithm use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generation weights:\n",
      "[2.7885359691576745, -9.49978489554666, -4.499413632617615, -5.5357852370235445, 4.729424283280249, 3.533989748458225, 7.843591354096908, -8.261223347411677, -1.561563606294591, -9.404055611238594, -5.627240503927933, 0.10710576206724731, -9.469280606322727]\n"
     ]
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "\n",
    "def make_all_data():\n",
    "    weights = [20.0*random.random()-10.0 for i in range(num_features+1)]\n",
    "    # weights = np.array(weights)\n",
    "    result = [[0 for j in range(num_features+1)]\n",
    "              for i in range(num_rows)]\n",
    "    \n",
    "    for i in range(num_rows):\n",
    "        y = weights[0]\n",
    "        for j in range(num_features):\n",
    "            x = 20.0*random.random() - 10.0\n",
    "            result[i][j] = x\n",
    "            wx = x * weights[j+1] # weight * x\n",
    "            y += wx\n",
    "            y += num_features*random.random()\n",
    "        if y > num_features:\n",
    "            result[i][num_features] = 1.0\n",
    "        else:\n",
    "            result[i][num_features] = 0.0\n",
    "    \n",
    "    print(\"Data generation weights:\")\n",
    "    print(weights)\n",
    "    \n",
    "    return result\n",
    "\n",
    "all_data = make_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "\n",
      "[9.093842867305796, 8.582512498031448, -2.5154950969167533, -9.227612707342237, 5.56237520665616, 8.203223845987466, -1.2762408148880766, -3.6914724212230894, -6.43479135867405, -6.38399926947293, -3.3642956262958297, 2.7040454220050982, 1.0]\n",
      "[3.6264345924366204, -9.864493165777846, 4.242274277577744, -7.6063323356776085, 2.277009198610296, 4.607606852234484, -5.024009349974701, 5.176420061229196, -6.375238145964213, -0.10049898495270071, -8.217885480201033, 1.480057791013806, 1.0]\n",
      "[-9.924396467712373, 5.772048426322042, -5.731118221069183, 5.469136351103792, 2.508336264596334, 8.272219170373823, -0.6512116690185472, 8.784668903862272, 4.519531355236772, -9.324601746359226, 8.57159574311044, -9.434456985367374, 1.0]\n",
      "...\n",
      "\n",
      "Test data:\n",
      "\n",
      "[9.093842867305796, 8.582512498031448, -2.5154950969167533, -9.227612707342237, 5.56237520665616, 8.203223845987466, -1.2762408148880766, -3.6914724212230894, -6.43479135867405, -6.38399926947293, -3.3642956262958297, 2.7040454220050982, 1.0]\n",
      "[3.6264345924366204, -9.864493165777846, 4.242274277577744, -7.6063323356776085, 2.277009198610296, 4.607606852234484, -5.024009349974701, 5.176420061229196, -6.375238145964213, -0.10049898495270071, -8.217885480201033, 1.480057791013806, 1.0]\n",
      "[-9.924396467712373, 5.772048426322042, -5.731118221069183, 5.469136351103792, 2.508336264596334, 8.272219170373823, -0.6512116690185472, 8.784668903862272, 4.519531355236772, -9.324601746359226, 8.57159574311044, -9.434456985367374, 1.0]\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "\n",
    "def make_train_test():\n",
    "    tot_rows = num_rows\n",
    "    num_train_rows = int(tot_rows * 0.80) # 80% hard-coded\n",
    "    num_test_rows = tot_rows - num_train_rows\n",
    "    \n",
    "    copy_data = copy.copy(all_data)\n",
    "    random.shuffle(copy_data)\n",
    "    \n",
    "    train_data = [copy_data[i] for i in range(num_train_rows)]\n",
    "    test_data = [copy_data[i+num_train_rows] for i in range(num_test_rows)]\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "train_data, test_data = make_train_test()\n",
    "print(\"Training data:\\n\")\n",
    "for i in range(3):\n",
    "    print(train_data[i])\n",
    "print(\"...\\n\")\n",
    "\n",
    "print(\"Test data:\\n\")\n",
    "for i in range(3):\n",
    "    print(train_data[i])\n",
    "print(\"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self, position, error, velocity, best_position, best_error):\n",
    "        self.position = position # equivalent to weights\n",
    "        self.error = error # measure of fitness\n",
    "        self.velocity = velocity # determines new position\n",
    "        self.best_position = best_position # best found by this Particle\n",
    "        self.bestError = best_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating LR binary classifier\n",
      "Starting training using no regularization\n",
      "<__main__.Particle object at 0x066E10F0>\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'velocity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-b1bee80494cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[0mlc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Starting training using no regularization\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best weights found:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-73-b1bee80494cd>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, alpha1, alpha2)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[1;31m# 1. compute new velocity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvelocity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# each x value of the velocity\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m                         \u001b[0mr1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                         \u001b[0mr2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'velocity'"
     ]
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "\n",
    "class LogisticClassifier:\n",
    "    def __init__(self):\n",
    "        self.num_features = num_features\n",
    "        self.weights = [0.0 for i in range(num_features+1)]\n",
    "    \n",
    "    def find_good_L1_weight(self):\n",
    "        pass\n",
    "    \n",
    "    def find_good_L2_weight(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, alpha1, alpha2):\n",
    "        # use PSO. particle position == LR weights\n",
    "        num_particles = 10\n",
    "        prob_death = 0.005\n",
    "        dim = self.num_features + 1 # need one wt for each feature, plus the b0 constant\n",
    "        \n",
    "        epoch = 0\n",
    "        minX = -10.0 # for each weight. assumes data has been normalized about 0\n",
    "        maxX = 10.0\n",
    "        w = 0.729 # inertia weight\n",
    "        c1 = 1.49445 # cognitive/local weight\n",
    "        c2 = 1.49445 # social/global weight\n",
    "        r1, r2 = 0.0, 0.0 # cognitive and social randomizations\n",
    "\n",
    "        swarm = [0.0 for i in range(num_particles)]\n",
    "        # best solution found by any particle in the swarm. implicit initialization to all 0.0\n",
    "        best_swarm_position = [0.0 for i in range(dim)]\n",
    "        best_swarm_error = sys.float_info.max # smaller values better\n",
    "        \n",
    "        for i in range(len(swarm)):\n",
    "            random_position = [0.0 for j in range(dim)]\n",
    "            for j in range(len(random_position)):\n",
    "                random_position[j] = (maxX - minX) * random.random() + minX\n",
    "                \n",
    "            # random_position is a set of weights\n",
    "            error_ = self.error(random_position, alpha1, alpha2);\n",
    "            random_velocity = [0.0 for i in range(dim)]\n",
    "            for j in range(len(random_velocity)):\n",
    "                lo = 0.1 * minX\n",
    "                hi = 0.1 * maxX\n",
    "                random_velocity[j] = (hi - lo) * random.random() + lo;\n",
    "            \n",
    "            # last two are best-position and best-error\n",
    "            swarm[i] = Particle(random_position, error_, random_velocity, random_position, error_)\n",
    "\n",
    "            # does current Particle have global best position/solution?\n",
    "            if swarm[i].error < best_swarm_error:\n",
    "                best_swarm_error = swarm[i].error\n",
    "                best_swarm_position = copy.copy(swarm[i].position)\n",
    "            # initialization     \n",
    "            for i in range(len(swarm)):\n",
    "                print(swarm[i])\n",
    "            \n",
    "            # main PSO algorithm\n",
    "            sequence = [i for i in range(num_particles)] # process particles in random order\n",
    "            \n",
    "            for epoch in range(max_epochs):\n",
    "                new_velocity = [0.0 for i in range(dim)] # step 1\n",
    "                new_position = [0.0 for i in range(dim)] # step 2\n",
    "                new_error = 0.0 # step 3\n",
    "                random.shuffle(sequence) # move particles in random sequence\n",
    "                \n",
    "                for pi in range(len(swarm)): # each Particle (index)\n",
    "                    i = sequence[pi]\n",
    "                    print(len(swarm))\n",
    "                    currP = swarm[i] # for coding convenience\n",
    "\n",
    "                    # 1. compute new velocity\n",
    "                    for j in range(len(currP.velocity)): # each x value of the velocity\n",
    "                        r1 = random.random()\n",
    "                        r2 = random.random()\n",
    "                        \n",
    "                        # velocity depends on old velocity, best position of parrticle, and \n",
    "                        # best position of any particle\n",
    "                        new_velocity[j] = (w * currP.velocity[j]) + (c1 * r1 * (currP.best_position[j] - currP.position[j])) + (c2 * r2 * (best_swarm_position[j] - currP.position[j]))\n",
    "                        \n",
    "                    currP.velocity = copy.copy(new_velocity)\n",
    "\n",
    "                    # 2. use new velocity to compute new position\n",
    "                    for j in range(len(currP.position)):\n",
    "                        new_position[j] = currP.position[j] + new_velocity[j] # compute new position\n",
    "                        if new_position[j] < minX: # keep in range\n",
    "                            new_position[j] = minX\n",
    "                        elif new_position[j] > maxX:\n",
    "                            new_position[j] = maxX\n",
    "\n",
    "                    new_position = copy.copy(currP.position)\n",
    "\n",
    "                    # 3. use new position to compute new error\n",
    "                    new_error = error(new_position, alpha1, alpha2)\n",
    "                    currP.error = new_error;\n",
    "\n",
    "                    if new_error < currP.best_error: # new particle best?\n",
    "                        currP.best_position = copy.copy(new_position)\n",
    "                        currP.best_error = new_error\n",
    "\n",
    "                    if (new_error < best_swarm_error): # new swarm best?\n",
    "                        best_swarm_position = copy.copy(new_position)\n",
    "                        best_swarm_error = new_error\n",
    "                        \n",
    "                    # 4. optional: does curr particle die?\n",
    "                    die = random.random()\n",
    "                    if die < probDeath:\n",
    "                        # new position, leave velocity, update error\n",
    "                        for j in range(len(currP.position)):\n",
    "                            currP.position[j] = (maxX - minX) * random.random() + minX\n",
    "                        currP.error = error(currP.position, alpha1, alpha2)\n",
    "                        currP.best_position = currP.position\n",
    "                        currP.best_error = currP.error\n",
    "\n",
    "                        if currP.error < best_swarm_error: # swarm best by chance?\n",
    "                            best_swarm_error = currP.error\n",
    "                            best_swarm_position = copy.copy(currP.position)\n",
    "        \n",
    "        ret_result = copy.copy(best_swarm_position)\n",
    "        return ret_result\n",
    "    \n",
    "    def accuracy(self, weights):\n",
    "        num_correct = 0\n",
    "        num_wrong = 0\n",
    "        y_index = len(train_data[0]) - 1\n",
    "        \n",
    "        for i in range(len(train_data)):\n",
    "            computed = compute_dependent(train_data[i], weights) # implicit cast\n",
    "            desired = train_data[i][y_index] # 0.0 or 1.0\n",
    "\n",
    "            epsilon = 0.0000000001\n",
    "            if math.fabs(computed - desired) < epsilon:\n",
    "                ++num_correct\n",
    "            else:\n",
    "                ++num_wrong\n",
    "        return (num_correct * 1.0) / (num_wrong + num_correct)\n",
    "    \n",
    "    def error(self, weights, alpha1, alpha2):\n",
    "        # mean squared error using supplied weights\n",
    "        # L1 regularization adds the sum of the absolute values of the weights\n",
    "        # L2 regularization adds the sqrt of sum of squared values\n",
    "\n",
    "        y_index = len(train_data[0]) - 1 # y-value (0/1) is last column\n",
    "        sum_squared_error = 0.0\n",
    "        for i in range(len(train_data)):\n",
    "            computed = self.compute_output(train_data[i], weights);\n",
    "            desired = train_data[i][y_index] # ex: 0.0 or 1.0\n",
    "            sum_squared_error += (computed - desired) * (computed - desired)\n",
    "\n",
    "        sum_abs_vals = 0.0 # L1 penalty\n",
    "        for i in range(len(weights)):\n",
    "            sum_abs_vals += math.fabs(weights[i])\n",
    "\n",
    "        sum_squared_vals = 0.0 # L2 penalty\n",
    "        for i in range(len(weights)):\n",
    "            sum_squared_vals += (weights[i] * weights[i])\n",
    "        # root_sum = math.sqrt(sum_squared_vals);\n",
    "\n",
    "        return (sum_squared_error / len(train_data)) + (alpha1 * sum_abs_vals) + (alpha2 * sum_squared_vals)\n",
    "    \n",
    "    def compute_output(self, data_item, weights):\n",
    "        z = 0.0\n",
    "\n",
    "        z += weights[0] # the b0 constant\n",
    "        for i in range(len(weights)-1): # data might include Y\n",
    "            z += (weights[i + 1] * data_item[i]) # skip first weight\n",
    "        return 1.0 / (1.0 + math.exp(-z))\n",
    "    \n",
    "    def compute_dependent(self, data_item, weights):\n",
    "        sum_ = compute_output(data_item, weights);\n",
    "\n",
    "        if sum_ <= 0.5:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "print(\"Creating LR binary classifier\")\n",
    "lc = LogisticClassifier()\n",
    "print(\"Starting training using no regularization\")\n",
    "weights = lc.train(0.0, 0.0)\n",
    "\n",
    "print(\"Best weights found:\")\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_vector():\n",
    "    pass\n",
    "\n",
    "max_epochs = 1000\n",
    "print(\"\\nStarting training using no regularization\")\n",
    "weights = lc.train(train_data, max_epochs, seed, 0.0, 0.0);\n",
    "\n",
    "print(\"\\nBest weights found:\")\n",
    "show_vector(weights)\n",
    "\n",
    "train_accuracy = lc.accuracy(train_data, weights);\n",
    "print(\"Prediction accuracy on training data = %f\" % train_accuracy)\n",
    "\n",
    "test_accuracy = lc.accuracy(test_data, weights);\n",
    "print(\"Prediction accuracy on training data = %f\" % test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
